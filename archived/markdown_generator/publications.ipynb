{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\texcerpt\tcitation\turl_slug\tpaper_url\n",
      "2020-05-01\tThe Margarita Dialogue Corpus: A Data Set for Time-Offset Interactions and Unstructured Dialogue Systems.\tThe 12th Language Resources and Evaluation Conference\t\"Time-Offset Interaction Applications (TOIAs) are systems that simulate face-to-face conversations between humans and digital human avatars recorded in the past. Developing a well-functioning TOIA involves several research areas: artificial intelligence, human-computer interaction, natural language processing, question answering, and dialogue systems. The first challenges are to define a sensible methodology for data collection and to create useful data sets for training the system to retrieve the best answer to a user's question. In this paper, we present three main contributions: a methodology for creating the knowledge base for a TOIA, a dialogue corpus, and baselines for single-turn answer retrieval. We develop the methodology using a two-step strategy. First, we let the avatar maker list pairs by intuition, guessing what possible questions a user may ask to the avatar. Second, we record actual dialogues between random individuals and the avatar-maker. We make the Margarita Dialogue Corpus available to the research community. This corpus comprises the knowledge base in text format, the video clips for each answer, and the annotated dialogues.\"\t\"Chierici, Alberto, Nizar Habash, and Margarita Bicec. \"\"The Margarita Di- alogue Corpus: A Data Set for Time-Offset Interactions and Unstructured Dialogue Systems.\"\" In Proceedings of The 12th Language Resources and Evaluation Conference, pp. 476-484. 2020.\"\tchierici-margarita\thttp://amchierici.github.io/files/Chierici2020margarita.pdf\n",
      "2021-04-01\tA View From The Crowd: Evaluation Challenges for Time-Offset Interaction Applications.\tProceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)\t\"Dialogue systems like chatbots, and tasks like question-answering (QA) have gained traction in recent years; yet evaluating such systems remains difficult. Reasons include the great variety in contexts and use cases for these systems as well as the high cost of human evaluation. In this paper, we focus on a specific type of dialogue systems: Time-Offset Interaction Applications (TOIAs) are intelligent, conversational software that simulates face-to-face conversations between humans and pre-recorded human avatars. Under the constraint that a TOIA is a single output system interacting with users with different expectations, we identify two challenges: first, how do we define a 'good' answer? and second, what's an appropriate metric to use? We explore both challenges through the creation of a novel dataset that identifies multiple good answers to specific TOIA questions through the help of Amazon Mechanical Turk workers. This 'view from the crowd' allows us to study the variations of how TOIA interrogators perceive its answers. Our contributions include the annotated dataset that we make publicly available and the proposal of Success Rate @k as an evaluation metric that is more appropriate than the traditional QA's and information retrieval's metrics.\"\t\"Chierici, Alberto, and Nizar Habash. \"\"A View From The Crowd: Evaluation Challenges for Time-Offset Interaction Applications.\"\" In Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pp. 75-85. 2021.\"\tchierici-view\thttp://amchierici.github.io/files/Chierici2021view.pdf\n",
      "2021-07-01\tA Cloud-based User-Centered Time-Offset Interaction Application.\tProceedings of the 22nd Annual SIGdial Meeting on Discourse and Dialogue\t\"Time-offset interaction applications (TOIA) allow simulating conversations with people who have previously recorded relevant video utterances, which are played in response to their interacting user. TOIAs have great potential for preserving cross-generational and cross-cultural histories, online teaching, simulated interviews, etc. Current TOIAs exist in niche contexts involving high production costs. Democratizing TOIA presents different challenges when creating appropriate pre-recordings, designing different user stories, and creating simple online interfaces for experimentation. We open-source TOIA 2.0, a user-centered time-offset interaction application, and make it available for everyone who wants to interact with people's pre-recordings, or create their pre-recordings.\"\t\"Chierici, Alberto, Tyeece Hensley, Wahib Kamran, Kertu Koss, Armaan Agrawal, Erin Meekhof, Goffredo Puccetti, and Nizar Habash . \"\"A Cloud- based User-Centered Time-Offset Interaction Application.\"\" Accepted for the 22nd Annual SIGdial Meeting on Discourse and Dialogue. 2021.\"\tchierici-cloud\thttp://amchierici.github.io/files/Chierici2021cloud.pdf"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>citation</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>The Margarita Dialogue Corpus: A Data Set for ...</td>\n",
       "      <td>The 12th Language Resources and Evaluation Con...</td>\n",
       "      <td>Time-Offset Interaction Applications (TOIAs) a...</td>\n",
       "      <td>Chierici, Alberto, Nizar Habash, and Margarita...</td>\n",
       "      <td>chierici-margarita</td>\n",
       "      <td>http://amchierici.github.io/files/Chierici2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>A View From The Crowd: Evaluation Challenges f...</td>\n",
       "      <td>Proceedings of the Workshop on Human Evaluatio...</td>\n",
       "      <td>Dialogue systems like chatbots, and tasks like...</td>\n",
       "      <td>Chierici, Alberto, and Nizar Habash. \"A View F...</td>\n",
       "      <td>chierici-view</td>\n",
       "      <td>http://amchierici.github.io/files/Chierici2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>A Cloud-based User-Centered Time-Offset Intera...</td>\n",
       "      <td>Proceedings of the 22nd Annual SIGdial Meeting...</td>\n",
       "      <td>Time-offset interaction applications (TOIA) al...</td>\n",
       "      <td>Chierici, Alberto, Tyeece Hensley, Wahib Kamra...</td>\n",
       "      <td>chierici-cloud</td>\n",
       "      <td>http://amchierici.github.io/files/Chierici2021...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                              title  \\\n",
       "0  2020-05-01  The Margarita Dialogue Corpus: A Data Set for ...   \n",
       "1  2021-04-01  A View From The Crowd: Evaluation Challenges f...   \n",
       "2  2021-07-01  A Cloud-based User-Centered Time-Offset Intera...   \n",
       "\n",
       "                                               venue  \\\n",
       "0  The 12th Language Resources and Evaluation Con...   \n",
       "1  Proceedings of the Workshop on Human Evaluatio...   \n",
       "2  Proceedings of the 22nd Annual SIGdial Meeting...   \n",
       "\n",
       "                                             excerpt  \\\n",
       "0  Time-Offset Interaction Applications (TOIAs) a...   \n",
       "1  Dialogue systems like chatbots, and tasks like...   \n",
       "2  Time-offset interaction applications (TOIA) al...   \n",
       "\n",
       "                                            citation            url_slug  \\\n",
       "0  Chierici, Alberto, Nizar Habash, and Margarita...  chierici-margarita   \n",
       "1  Chierici, Alberto, and Nizar Habash. \"A View F...       chierici-view   \n",
       "2  Chierici, Alberto, Tyeece Hensley, Wahib Kamra...      chierici-cloud   \n",
       "\n",
       "                                           paper_url  \n",
       "0  http://amchierici.github.io/files/Chierici2020...  \n",
       "1  http://amchierici.github.io/files/Chierici2021...  \n",
       "2  http://amchierici.github.io/files/Chierici2021...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "        \n",
    "    md += \"\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01-chierici-margarita.md 2021-07-01-chierici-cloud.md\n",
      "2021-04-01-chierici-view.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"A View From The Crowd: Evaluation Challenges for Time-Offset Interaction Applications.\"\n",
      "collection: publications\n",
      "permalink: /publication/2021-04-01-chierici-view\n",
      "excerpt: 'Dialogue systems like chatbots, and tasks like question-answering (QA) have gained traction in recent years; yet evaluating such systems remains difficult. Reasons include the great variety in contexts and use cases for these systems as well as the high cost of human evaluation. In this paper, we focus on a specific type of dialogue systems: Time-Offset Interaction Applications (TOIAs) are intelligent, conversational software that simulates face-to-face conversations between humans and pre-recorded human avatars. Under the constraint that a TOIA is a single output system interacting with users with different expectations, we identify two challenges: first, how do we define a &apos;good&apos; answer? and second, what&apos;s an appropriate metric to use? We explore both challenges through the creation of a novel dataset that identifies multiple good answers to specific TOIA questions through the help of Amazon Mechanical Turk workers. This &apos;view from the crowd&apos; allows us to study the variations of how TOIA interrogators perceive its answers. Our contributions include the annotated dataset that we make publicly available and the proposal of Success Rate @k as an evaluation metric that is more appropriate than the traditional QA&apos;s and information retrieval&apos;s metrics.'\n",
      "date: 2021-04-01\n",
      "venue: 'Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)'\n",
      "paperurl: 'http://amchierici.github.io/files/Chierici2021view.pdf'\n",
      "citation: 'Chierici, Alberto, and Nizar Habash. &quot;A View From The Crowd: Evaluation Challenges for Time-Offset Interaction Applications.&quot; In Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pp. 75-85. 2021.'\n",
      "---\n",
      "Dialogue systems like chatbots, and tasks like question-answering (QA) have gained traction in recent years; yet evaluating such systems remains difficult. Reasons include the great variety in contexts and use cases for these systems as well as the high cost of human evaluation. In this paper, we focus on a specific type of dialogue systems: Time-Offset Interaction Applications (TOIAs) are intelligent, conversational software that simulates face-to-face conversations between humans and pre-recorded human avatars. Under the constraint that a TOIA is a single output system interacting with users with different expectations, we identify two challenges: first, how do we define a &apos;good&apos; answer? and second, what&apos;s an appropriate metric to use? We explore both challenges through the creation of a novel dataset that identifies multiple good answers to specific TOIA questions through the help of Amazon Mechanical Turk workers. This &apos;view from the crowd&apos; allows us to study the variations of how TOIA interrogators perceive its answers. Our contributions include the annotated dataset that we make publicly available and the proposal of Success Rate @k as an evaluation metric that is more appropriate than the traditional QA&apos;s and information retrieval&apos;s metrics.\n",
      "\n",
      "[Download paper here](http://amchierici.github.io/files/Chierici2021view.pdf)\n",
      "\n",
      "Recommended citation: Chierici, Alberto, and Nizar Habash. \"A View From The Crowd: Evaluation Challenges for Time-Offset Interaction Applications.\" In Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pp. 75-85. 2021."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2021-04-01-chierici-view.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
